{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load-digits\r\n",
    "test_size = 0.2, random-state = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\r\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(digits.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\r\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature 데이터\r\n",
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "    X, y, stratify=digits.target,\r\n",
    "    test_size=0.2, random_state=2021\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 스케일링 비교해 SVC로 데이터셋 학습해보기\r\n",
    "[참고] https://realblack0.github.io/2020/03/29/normalization-standardization-regularization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) StandardScaler\r\n",
    "각 feature의 평균을 0, 분산을 1로 변경합니다. 모든 특성들이 같은 스케일을 갖게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled test accuracy : 0.981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "scaler = StandardScaler()\r\n",
    "svc = SVC()\r\n",
    "X_train_scale = scaler.fit_transform(X_train)\r\n",
    "X_test_scale = scaler.transform(X_test)\r\n",
    "svc.fit(X_train_scale, y_train)\r\n",
    "print('Scaled test accuracy : %.3f' %(svc.score(X_test_scale,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) RobustScaler\r\n",
    "모든 특성들이 같은 크기를 갖는다는 점에서 StandardScaler와 비슷하지만, 평균과 분산 대신 median과 quartile을 사용한다. RobustScaler는 이상치에 영향을 받지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled test accuracy : 0.956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\r\n",
    "scaler = RobustScaler()\r\n",
    "svc = SVC()\r\n",
    "X_train_scale = scaler.fit_transform(X_train)\r\n",
    "X_test_scale = scaler.transform(X_test)\r\n",
    "svc.fit(X_train_scale, y_train)\r\n",
    "print('Scaled test accuracy : %.3f' %(svc.score(X_test_scale,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) MinMaxScaler\r\n",
    "모든 feature가 0과 1사이에 위치하게 만든다. 데이터가 2차원 셋일 경우, 모든 데이터는 x축의 0과 1 사이에, y축의 0과 1사이에 위치하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled test accuracy : 0.986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "scaler = MinMaxScaler()\r\n",
    "svc = SVC()\r\n",
    "X_train_scale = scaler.fit_transform(X_train)\r\n",
    "X_test_scale = scaler.transform(X_test)\r\n",
    "svc.fit(X_train_scale, y_train)\r\n",
    "print('Scaled test accuracy : %.3f' %(svc.score(X_test_scale,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Normalizer\r\n",
    "StandardScaler, RobustScaler, MinMaxScaler가 각 columns의 통계치를 이용한다면 Normalizer는 row마다 각각 정규화된다. Normalizer는 유클리드 거리가 1이 되도록 데이터를 조정한다. (유클리드 거리는 두 점 사이의 거리를 계산할 때 쓰는 방법, L2 Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled test accuracy : 0.986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\r\n",
    "scaler = Normalizer()\r\n",
    "svc = SVC()\r\n",
    "X_train_scale = scaler.fit_transform(X_train)\r\n",
    "X_test_scale = scaler.transform(X_test)\r\n",
    "svc.fit(X_train_scale, y_train)\r\n",
    "print('Scaled test accuracy : %.3f' %(svc.score(X_test_scale,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ※ StandardScaler code, RobustScaler code, MinMaxScaler code, Normalizer code로 각각 스케일링 한 후, 서포트 백터 머신으로 학습시켜보니 MinMaxScaler code, Normalizer code가 0.986으로 정확도가 가장 높았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 통해 나온 MinMaxScaler code, Normalizer code로 알고리즘 종류별 비교를 하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification(분류) 알고리즘 종류별 비교\r\n",
    "일련의 데이터가 포함되는 기존 카테고리들을 학습하고, 이것을 기반으로 컴퓨터는 데이터의 범주를 구분하여 경계를 나누는 것을 학습한다.  따라서 모델에 입력된 새로운 데이터는 해당 점이 어느 곳에 위치하느냐에 따라 가까운 카테고리 혹은 학습된 알고리즘에 의해 분류하게 되다.\r\n",
    "### [참고] https://bangu4.tistory.com/99 [방구의 개발냄새]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) KNN(K-nearest neighbor)\r\n",
    "실수 데이터의 경우 유클리드 거리 측정 방식을 사용하고, 범주형 혹은 이진 데이터와 같은 유형의 데이터는 해밍 거리 측정 방식을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled test accuracy : 0.978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "scaler = MinMaxScaler()\r\n",
    "X_train_scale = scaler.fit_transform(X_train)\r\n",
    "X_test_scale = scaler.transform(X_test)\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(n_neighbors=1) \r\n",
    "knn.fit(X_train_scale,y_train)\r\n",
    "\r\n",
    "print('Scaled test accuracy : %.3f' %(knn.score(X_test_scale,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Decision Tree(의사결정 트리)\r\n",
    "가장 단순한 classifier 중 하나로, decision tree와 같은 도구를 활용하여 모델을 그래프로 그리는 매우 단순한 구조로 되어 있다. 이 방식은 root에서부터 적절한 node를 선택하면서 진행하다가 최종 결정을 내리게 되는 model이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8777777777777778"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "scaler = MinMaxScaler()\r\n",
    "X_train_scale = scaler.fit_transform(X_train)\r\n",
    "X_test_scale = scaler.transform(X_test)\r\n",
    "\r\n",
    "dt_clf = DecisionTreeClassifier(random_state=2021)\r\n",
    "dt_clf.fit(X_train_scale, y_train)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "pred = dt_clf.predict(X_test_scale)\r\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Random Forest\r\n",
    "Decision tree가 여러개 모여 Forest를 이룬 것이다.\r\n",
    "\r\n",
    "Decision tree보다 작은 Tree가 여러개 모이게 되어, 모든 트리의 결과들을 합하여 더많은 값을 최종결과로 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9611111111111111"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "scaler = MinMaxScaler()\r\n",
    "X_train_scale = scaler.fit_transform(X_train)\r\n",
    "X_test_scale = scaler.transform(X_test)\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "rf_clf = RandomForestClassifier(random_state=2021)\r\n",
    "rf_clf.fit(X_train_scale,y_train)\r\n",
    "pred = rf_clf.predict(X_test_scale)\r\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) SVM (Support Vector Machine)\r\n",
    "서포터 벡터 머신은 기본적으로 Decision Boundary라는 직선이 주어진 상태\r\n",
    "\r\n",
    "앞서 스케일링하여 svm으로 데이터셋을 학습시켜봄\r\n",
    "MinMaxScaler code, Normalizer code가 가장 높게 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 서포터 백터 머신을 사용했을 때, 정확도가 가장 높게 나옴.\r\n",
    "그러므로 Grid search을 MinMaxScaler code, Normalizer code 스케일링한 svc에 사용하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMaxScaler로 스케일링한 후, svm 사용해 grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "scaler = MinMaxScaler()\r\n",
    "svc = SVC()\r\n",
    "X_train_scale = scaler.fit_transform(X_train)\r\n",
    "X_test_scale = scaler.transform(X_test)\r\n",
    "svc.fit(X_train_scale, y_train)\r\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고 점수: 0.98\n",
      "최적 파라미터: {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\r\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\r\n",
    "        # 매개변수의 각 조합에 대해 svc 훈련시킴\r\n",
    "\r\n",
    "        clf = SVC(gamma=gamma, C=C)\r\n",
    "        clf.fit(X_train_scale,y_train)\r\n",
    "        # 테스트 세트로 svc 평가\r\n",
    "        y_test_hat = clf.predict(X_test_scale)\r\n",
    "        score = accuracy_score(y_test, y_test_hat)\r\n",
    "        #점수가 더 높으면 매개변수와 함께 기록\r\n",
    "        if score > best_score:\r\n",
    "            best_score = score\r\n",
    "            best_parameters = {'C':C, 'gamma':gamma}\r\n",
    "\r\n",
    "print(\"최고 점수: {:.2f}\".format(best_score))\r\n",
    "print(\"최적 파라미터:\", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizer로 스케일링한 후, svm 사용해 grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\r\n",
    "scaler = Normalizer()\r\n",
    "svc = SVC()\r\n",
    "X_train_scale = scaler.fit_transform(X_train)\r\n",
    "X_test_scale = scaler.transform(X_test)\r\n",
    "svc.fit(X_train_scale, y_train)\r\n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고 점수: 0.98\n",
      "최적 파라미터: {'C': 1, 'gamma': 10}\n"
     ]
    }
   ],
   "source": [
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\r\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\r\n",
    "        # 매개변수의 각 조합에 대해 svc 훈련시킴\r\n",
    "\r\n",
    "        clf = SVC(gamma=gamma, C=C)\r\n",
    "        clf.fit(X_train_scale,y_train)\r\n",
    "        # 테스트 세트로 svc 평가\r\n",
    "        y_test_hat = clf.predict(X_test_scale)\r\n",
    "        score = accuracy_score(y_test, y_test_hat)\r\n",
    "        #점수가 더 높으면 매개변수와 함께 기록\r\n",
    "        if score > best_score:\r\n",
    "            best_score = score\r\n",
    "            best_parameters = {'C':C, 'gamma':gamma}\r\n",
    "\r\n",
    "print(\"최고 점수: {:.2f}\".format(best_score))\r\n",
    "print(\"최적 파라미터:\", best_parameters)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c1eae21719a0790335dcb83aad72b63b602cfe5cdb2bda0f60bc11d4f154e4b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}